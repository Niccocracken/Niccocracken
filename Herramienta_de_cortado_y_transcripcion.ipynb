{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN8JUYC5HePSNnoM/soeZoC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Niccocracken/Niccocracken/blob/main/Herramienta_de_cortado_y_transcripcion.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/openai/whisper.git\n",
        "!sudo apt update && sudo apt install ffmpeg\n",
        "\n",
        "# Importa las bibliotecas\n",
        "from pydub import AudioSegment\n",
        "import warnings\n",
        "import whisper\n",
        "import re\n",
        "import os\n",
        "\n",
        "# Carga el modelo de Whisper\n",
        "model = whisper.load_model(\"small\")\n",
        "\n",
        "# Desactiva los mensajes de advertencia\n",
        "warnings.simplefilter(\"ignore\")"
      ],
      "metadata": {
        "collapsed": true,
        "id": "WCreGpHO3sjg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define la ruta del audio\n",
        "audio_ruta = input(\"Ruta del archivo: \")\n",
        "\n",
        "# Carpeta donde se guardan los archivos de audio segmentados y transcripciones\n",
        "carpeta_salida = \"/content/transcripciones/\"\n",
        "\n",
        "# Se asegura de que la carpeta exista\n",
        "if not os.path.exists(carpeta_salida):\n",
        "    os.makedirs(carpeta_salida)\n",
        "\n",
        "# Carga el audio\n",
        "try:\n",
        "    audio = AudioSegment.from_file(audio_ruta)\n",
        "except Exception as e:\n",
        "    print(f\"Error cargando el audio: {e}\")\n",
        "    exit() # Sale si el audio no pudo ser cargado\n",
        "\n",
        "duracion = len(audio)  # Duracion total del audio en milisegundos\n",
        "segmento_duracion = 5 * 53000  # Duracion de cada segmento de audio en milisegundos (15 minutes)\n",
        "\n",
        "transcripciones = []\n",
        "\n",
        "# Corta y transcribe\n",
        "for i in range(0, duracion, segmento_duracion):\n",
        "    tiempo_inicio = i\n",
        "    tiempo_final = min(i + segmento_duracion, duracion)  # Asegura que el último segmento no exceda el total del audio\n",
        "\n",
        "    # Corta el audio\n",
        "    audio_segmento = audio[tiempo_inicio:tiempo_final]\n",
        "\n",
        "    # Define el nombre del archivo para cada segmento\n",
        "    segmento_indice = i // segmento_duracion + 1\n",
        "    segmento_nombre = os.path.join(carpeta_salida, f\"audio_segmento_{segmento_indice}.mp3\")\n",
        "    transcripcion_nombre = os.path.join(carpeta_salida, f\"transcripcion_audio_{segmento_indice}.txt\")\n",
        "\n",
        "    # Exporta el segmento de audio\n",
        "    try:\n",
        "        audio_segmento.export(segmento_nombre, format=\"mp3\")\n",
        "        print(f\"Exportado {segmento_nombre}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error exportando el audio: {segmento_nombre}: {e}\")\n",
        "        continue # Salta al siguiente segmento si falla la exportación\n",
        "\n",
        "    # Transcribe el segmmento de audio\n",
        "    if os.path.exists(segmento_nombre):\n",
        "        print(f\"Transcribiendo {segmento_nombre}...\")\n",
        "        try:\n",
        "            resultado = model.transcribe(segmento_nombre)\n",
        "            transcripcion_texto = resultado[\"text\"]\n",
        "\n",
        "            # Separa párrafos de acuerdo al punto\n",
        "            transcripcion_texto_formateado = re.sub(r'(?<!\\d)(?<!\\.)\\.(?!\\.)', '.\\n\\n', transcripcion_texto)\n",
        "\n",
        "            # Elimina los espacios iniciales de cada línea\n",
        "            transcripcion_texto_formateado = re.sub(r'^[ \\t]+(?=\\S)', '', transcripcion_texto_formateado, flags=re.MULTILINE)\n",
        "\n",
        "            # Guarda la transcripcion en un .txt\n",
        "            with open(transcripcion_nombre, \"w\") as f:\n",
        "                f.write(transcripcion_texto_formateado)\n",
        "\n",
        "            print(f\"Transcripcion guardada en {transcripcion_nombre}\")\n",
        "            transcripciones.append((segmento_indice, transcripcion_texto_formateado)) # Almacena transcripcion con su indice\n",
        "        except Exception as e:\n",
        "            print(f\"Error transcribiendo {segmento_nombre}: {e}\")\n",
        "    else:\n",
        "        print(f\"Segmento no encontrado: {segmento_nombre}\")\n",
        "\n",
        "print(\"Proceso de cortado y transcripcion completado.\")\n",
        "\n",
        "# Organiza las transcripciones por su indice\n",
        "transcripciones.sort(key=lambda item: item[0])\n",
        "\n",
        "# Combina todas las transcripciones en un solo archivo\n",
        "archivo_combinado_salida = os.path.join(carpeta_salida, \"transcripcion_audio_completa.txt\")\n",
        "\n",
        "with open(archivo_combinado_salida, 'w') as archivo_salida:\n",
        "    for index, transcripcion in transcripciones:\n",
        "        archivo_salida.write(transcripcion)\n",
        "\n",
        "print(f\"Todas las transcripciones han sido combinadas en {archivo_combinado_salida}\")\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "-OK0SGyTay-L"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}